{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b32da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Procurando arquivos em: /home/mike/Downloads/SBD2-Austin-Airbnb/Data Layer/raw\n",
      " Arquivo Listings ENCONTRADO!\n",
      " Arquivo Calendar ENCONTRADO!\n",
      " Arquivo Reviews ENCONTRADO!\n",
      "\n",
      " Sucesso! Os DataFrames da camada RAW foram carregados.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Como o notebook est√° em /Transformer e o na raiz\n",
    "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), '.env'))\n",
    "\n",
    "# 2. CONFIGURAR CAMINHOS BASEADOS NA ESTRUTURA DE PASTAS\n",
    "RAIZ_PROJETO = os.path.dirname(os.getcwd())\n",
    "BASE_PATH = os.path.join(RAIZ_PROJETO, \"Data Layer\", \"raw\")\n",
    "\n",
    "print(f\"Procurando arquivos em: {BASE_PATH}\")\n",
    "\n",
    "# 3. DICION√ÅRIO E VALIDA√á√ÉO\n",
    "arquivos = {\n",
    "    \"Listings\": \"dados_brutos_listings.csv\",\n",
    "    \"Calendar\": \"dados_brutos_calendar.csv\",\n",
    "    \"Reviews\": \"dados_brutos_reviews.csv\"\n",
    "}\n",
    "\n",
    "for nome, arquivo in arquivos.items():\n",
    "    if os.path.exists(os.path.join(BASE_PATH, arquivo)):\n",
    "        print(f\" Arquivo {nome} ENCONTRADO!\")\n",
    "    else:\n",
    "        print(f\" ERRO: Arquivo {nome} N√ÉO encontrado!\")\n",
    "\n",
    "# 4. INICIAR SPARK \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL_Austin_Airbnb\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 5. EXTRA√á√ÉO\n",
    "try:\n",
    "    df_listings_raw = spark.read.csv(os.path.join(BASE_PATH, arquivos[\"Listings\"]), header=True, inferSchema=True)\n",
    "    df_calendar_raw = spark.read.csv(os.path.join(BASE_PATH, arquivos[\"Calendar\"]), header=True, inferSchema=True)\n",
    "    df_reviews_raw = spark.read.csv(os.path.join(BASE_PATH, arquivos[\"Reviews\"]), header=True, inferSchema=True)\n",
    "    print(\"\\nSucesso! Os DataFrames da camada RAW foram carregados.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nFalha na leitura: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f920a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Iniciando transforma√ß√£o completa dos dados...\n",
      "\n",
      "üìã Processando LISTINGS...\n",
      "   ‚úÖ 5,764 listings processados\n",
      "\n",
      "üìÖ Processando CALENDAR...\n",
      "   ‚úÖ 1,048,575 registros de calendar\n",
      "\n",
      "‚≠ê Processando REVIEWS...\n",
      "   ‚úÖ 62,976 reviews\n",
      "\n",
      "üîó Consolidando dados...\n",
      "   ‚úÖ 11,610,945 registros ap√≥s joins\n",
      "\n",
      "üßπ Removendo outliers de CALENDAR_PRICE (IQR method)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ 7,932,919 registros finais (limites: $-76.00 - $356.00)\n",
      "\n",
      "üíæ Carregando no PostgreSQL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SUCESSO! Banco de dados populado com dados completos!\n",
      "   üìä Total: 7,932,919 registros\n",
      "   üìã Colunas: 68\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "print(\"Iniciando transforma√ß√£o completa dos dados...\\n\")\n",
    "\n",
    "# ==================== 1. LIMPAR E TRANSFORMAR LISTINGS ====================\n",
    "print(\"Processando LISTINGS...\")\n",
    "\n",
    "df_listings = df_listings_raw.select(\n",
    "    # IDs e Nomes\n",
    "    F.expr(\"try_cast(id as int)\").alias(\"listing_id\"),\n",
    "    F.col(\"name\").cast(\"string\").alias(\"listing_name\"),\n",
    "    \n",
    "    # Tipos de Propriedade\n",
    "    F.col(\"property_type\").cast(\"string\"),\n",
    "    F.col(\"room_type\").cast(\"string\"),\n",
    "    F.col(\"bed_type\").cast(\"string\"),\n",
    "    \n",
    "    # Capacidade\n",
    "    F.expr(\"try_cast(accommodates as int)\").alias(\"accommodates\"),\n",
    "    F.expr(\"try_cast(bathrooms as int)\").alias(\"bathrooms\"),\n",
    "    F.expr(\"try_cast(bedrooms as int)\").alias(\"bedrooms\"),\n",
    "    F.expr(\"try_cast(beds as int)\").alias(\"beds\"),\n",
    "    \n",
    "    # Localiza√ß√£o\n",
    "    F.expr(\"try_cast(neighbourhood_cleansed as int)\").alias(\"neighbourhood_cleansed\"),\n",
    "    F.col(\"city\").cast(\"string\"),\n",
    "    F.col(\"state\").cast(\"string\"),\n",
    "    F.expr(\"try_cast(zipcode as double)\").alias(\"zipcode\"),\n",
    "    F.col(\"market\").cast(\"string\"),\n",
    "    F.col(\"country_code\").cast(\"string\"),\n",
    "    F.col(\"country\").cast(\"string\"),\n",
    "    F.expr(\"try_cast(latitude as decimal(10,8))\").alias(\"latitude\"),\n",
    "    F.expr(\"try_cast(longitude as decimal(11,8))\").alias(\"longitude\"),\n",
    "    F.when(F.col(\"is_location_exact\") == \"t\", True).otherwise(False).alias(\"is_location_exact\"),\n",
    "    \n",
    "    # Pre√ßos (limpeza completa)\n",
    "    F.expr(\"try_cast(regexp_replace(price, '[^0-9.]', '') as decimal(10,2))\").alias(\"listing_price\"),\n",
    "    F.expr(\"try_cast(regexp_replace(security_deposit, '[^0-9.]', '') as decimal(10,2))\").alias(\"security_deposit\"),\n",
    "    F.expr(\"try_cast(regexp_replace(cleaning_fee, '[^0-9.]', '') as decimal(10,2))\").alias(\"cleaning_fee\"),\n",
    "    F.expr(\"try_cast(guests_included as int)\").alias(\"guests_included\"),\n",
    "    F.expr(\"try_cast(regexp_replace(extra_people, '[^0-9.]', '') as decimal(10,2))\").alias(\"extra_people\"),\n",
    "    \n",
    "    # Pol√≠ticas\n",
    "    F.expr(\"try_cast(minimum_nights as int)\").alias(\"minimum_nights\"),\n",
    "    F.expr(\"try_cast(maximum_nights as int)\").alias(\"maximum_nights\"),\n",
    "    F.when(F.col(\"instant_bookable\") == \"t\", True).otherwise(False).alias(\"instant_bookable\"),\n",
    "    F.col(\"cancellation_policy\").cast(\"string\"),\n",
    "    F.when(F.col(\"require_guest_profile_picture\") == \"t\", True).otherwise(False).alias(\"require_guest_profile_picture\"),\n",
    "    F.when(F.col(\"require_guest_phone_verification\") == \"t\", True).otherwise(False).alias(\"require_guest_phone_verification\"),\n",
    "    \n",
    "    # Disponibilidade\n",
    "    F.expr(\"try_cast(availability_30 as int)\").alias(\"availability_30\"),\n",
    "    F.expr(\"try_cast(availability_60 as int)\").alias(\"availability_60\"),\n",
    "    F.expr(\"try_cast(availability_90 as int)\").alias(\"availability_90\"),\n",
    "    F.expr(\"try_cast(availability_365 as int)\").alias(\"availability_365\"),\n",
    "    \n",
    "    # Reviews\n",
    "    F.expr(\"try_cast(number_of_reviews as int)\").alias(\"number_of_reviews\"),\n",
    "    F.expr(\"try_cast(first_review as date)\").alias(\"first_review\"),\n",
    "    F.expr(\"try_cast(last_review as date)\").alias(\"last_review\"),\n",
    "    F.expr(\"try_cast(reviews_per_month as decimal(5,2))\").alias(\"reviews_per_month\"),\n",
    "    F.expr(\"try_cast(review_scores_rating as decimal(4,2))\").alias(\"review_scores_rating\"),\n",
    "    F.expr(\"try_cast(review_scores_accuracy as decimal(4,2))\").alias(\"review_scores_accuracy\"),\n",
    "    F.expr(\"try_cast(review_scores_cleanliness as decimal(4,2))\").alias(\"review_scores_cleanliness\"),\n",
    "    F.expr(\"try_cast(review_scores_checkin as decimal(4,2))\").alias(\"review_scores_checkin\"),\n",
    "    F.expr(\"try_cast(review_scores_communication as decimal(4,2))\").alias(\"review_scores_communication\"),\n",
    "    F.expr(\"try_cast(review_scores_location as decimal(4,2))\").alias(\"review_scores_location\"),\n",
    "    F.expr(\"try_cast(review_scores_value as decimal(4,2))\").alias(\"review_scores_value\"),\n",
    "    F.col(\"amenities\").cast(\"string\"),\n",
    "    \n",
    "    # Host\n",
    "    F.expr(\"try_cast(host_id as int)\").alias(\"host_id\"),\n",
    "    F.col(\"host_name\").cast(\"string\"),\n",
    "    F.expr(\"try_cast(host_since as date)\").alias(\"host_since\"),\n",
    "    F.col(\"host_location\").cast(\"string\"),\n",
    "    F.col(\"host_response_time\").cast(\"string\"),\n",
    "    F.col(\"host_response_rate\").cast(\"string\"),\n",
    "    F.col(\"host_acceptance_rate\").cast(\"string\"),\n",
    "    F.when(F.col(\"host_is_superhost\") == \"t\", True).otherwise(False).alias(\"host_is_superhost\"),\n",
    "    F.col(\"host_neighbourhood\").cast(\"string\"),\n",
    "    F.expr(\"try_cast(host_listings_count as int)\").alias(\"host_listings_count\"),\n",
    "    F.expr(\"try_cast(host_total_listings_count as int)\").alias(\"host_total_listings_count\"),\n",
    "    F.col(\"host_verifications\").cast(\"string\"),\n",
    "    F.when(F.col(\"host_has_profile_pic\") == \"t\", True).otherwise(False).alias(\"host_has_profile_pic\"),\n",
    "    F.when(F.col(\"host_identity_verified\") == \"t\", True).otherwise(False).alias(\"host_identity_verified\"),\n",
    "    F.expr(\"try_cast(calculated_host_listings_count as int)\").alias(\"calculated_host_listings_count\")\n",
    ").filter(F.col(\"listing_id\").isNotNull())\n",
    "\n",
    "print(f\"   {df_listings.count():,} listings processados\")\n",
    "\n",
    "# ==================== 2. LIMPAR CALENDAR ====================\n",
    "print(\"\\nProcessando CALENDAR...\")\n",
    "\n",
    "df_calendar = df_calendar_raw.select(\n",
    "    F.expr(\"try_cast(listing_id as int)\").alias(\"listing_id\"),\n",
    "    F.expr(\"try_cast(date as date)\").alias(\"calendar_date\"),\n",
    "    F.when(F.col(\"available\") == \"t\", True).otherwise(False).alias(\"calendar_available\"),\n",
    "    F.expr(\"try_cast(regexp_replace(price, '[^0-9.]', '') as decimal(10,2))\").alias(\"calendar_price\")\n",
    ").filter(F.col(\"listing_id\").isNotNull() & F.col(\"calendar_date\").isNotNull())\n",
    "\n",
    "print(f\"   {df_calendar.count():,} registros de calendar\")\n",
    "\n",
    "# ==================== 3. LIMPAR REVIEWS ====================\n",
    "print(\"\\nProcessando REVIEWS...\")\n",
    "\n",
    "df_reviews = df_reviews_raw.select(\n",
    "    F.expr(\"try_cast(listing_id as int)\").alias(\"listing_id\"),\n",
    "    F.expr(\"try_cast(id as int)\").alias(\"review_id\"),\n",
    "    F.expr(\"try_cast(date as date)\").alias(\"review_date\"),\n",
    "    F.expr(\"try_cast(reviewer_id as int)\").alias(\"reviewer_id\"),\n",
    "    F.col(\"reviewer_name\").cast(\"string\")\n",
    ").filter(F.col(\"listing_id\").isNotNull() & F.col(\"review_id\").isNotNull())\n",
    "\n",
    "print(f\"   {df_reviews.count():,} reviews\")\n",
    "\n",
    "# ==================== 4. CONSOLIDAR (ONE BIG TABLE) ====================\n",
    "print(\"\\nConsolidando dados...\")\n",
    "\n",
    "# INNER JOIN Calendar + Listings (s√≥ registros com listings v√°lidos)\n",
    "# Isso garante que is_location_exact e outras colunas obrigat√≥rias n√£o sejam NULL\n",
    "df_silver = df_calendar.join(df_listings, \"listing_id\", \"inner\")\n",
    "\n",
    "# LEFT JOIN Reviews (para manter registros sem reviews)\n",
    "df_silver = df_silver.join(df_reviews, [\"listing_id\"], \"left\")\n",
    "\n",
    "print(f\"   {df_silver.count():,} registros ap√≥s joins\")\n",
    "\n",
    "# ==================== 5. REMOVER OUTLIERS DE PRE√áO ====================\n",
    "print(\"\\nRemovendo outliers de CALENDAR_PRICE (IQR method)...\")\n",
    "\n",
    "# Filtrar outliers baseado no pre√ßo di√°rio do calendar, n√£o do listing\n",
    "percentis = df_silver.approxQuantile(\"calendar_price\", [0.25, 0.75], 0.01)\n",
    "Q1, Q3 = percentis[0], percentis[1]\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "df_silver = df_silver.filter(\n",
    "    (F.col(\"calendar_price\") >= lower) & \n",
    "    (F.col(\"calendar_price\") <= upper) &\n",
    "    (F.col(\"calendar_price\") > 0)\n",
    ")\n",
    "\n",
    "print(f\"   {df_silver.count():,} registros finais (limites: ${lower:.2f} - ${upper:.2f})\")\n",
    "\n",
    "# ==================== 6. CARREGAR NO POSTGRES ====================\n",
    "print(\"\\nCarregando no PostgreSQL...\")\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5433/austin_airbnb\"\n",
    "db_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_silver.write.jdbc(\n",
    "        url=jdbc_url, \n",
    "        table=\"silver.one_big_table\", \n",
    "        mode=\"append\",\n",
    "        properties=db_properties\n",
    "    )\n",
    "    print(\"\\nSUCESSO! Banco de dados populado com dados completos!\")\n",
    "    print(f\"   Total: {df_silver.count():,} registros\")\n",
    "    print(f\"   Colunas: {len(df_silver.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro na carga: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3c341e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros no banco: 7,932,919\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(host=\"localhost\", port=\"5433\", database=\"austin_airbnb\", user=\"postgres\", password=\"postgres\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT count(*) FROM silver.one_big_table\")\n",
    "print(f\"Total de registros no banco: {cur.fetchone()[0]:,}\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d5566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Exibindo 10 linhas da tabela silver.one_big_table ---\n",
      "\n",
      "ID: 3862246 | Data: 2015-11-09 | Pre√ßo: $None | Nome: East Side Bungalow / Private S...\n",
      "ID: 3862246 | Data: 2015-11-09 | Pre√ßo: $None | Nome: East Side Bungalow / Private S...\n",
      "ID: 3862246 | Data: 2015-11-09 | Pre√ßo: $None | Nome: East Side Bungalow / Private S...\n",
      "ID: 5785387 | Data: 2016-02-07 | Pre√ßo: $None | Nome: Cute Shabby Chic Room in E. Au...\n",
      "ID: 3862246 | Data: 2015-11-09 | Pre√ßo: $None | Nome: East Side Bungalow / Private S...\n",
      "ID: 5785387 | Data: 2016-02-07 | Pre√ßo: $None | Nome: Cute Shabby Chic Room in E. Au...\n",
      "ID: 3862246 | Data: 2015-11-09 | Pre√ßo: $None | Nome: East Side Bungalow / Private S...\n",
      "ID: 5785387 | Data: 2016-02-07 | Pre√ßo: $None | Nome: Cute Shabby Chic Room in E. Au...\n",
      "ID: 3862246 | Data: 2015-11-09 | Pre√ßo: $None | Nome: East Side Bungalow / Private S...\n",
      "ID: 5785387 | Data: 2016-02-08 | Pre√ßo: $None | Nome: Cute Shabby Chic Room in E. Au...\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "try:\n",
    "    # 1. Conectar ao banco\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\", \n",
    "        port=\"5433\", \n",
    "        database=\"austin_airbnb\", \n",
    "        user=\"postgres\", \n",
    "        password=\"postgres\"\n",
    "    )\n",
    "    \n",
    "    # 2. Criar um cursor (usando RealDictCursor para ver os nomes das colunas como um dicion√°rio)\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    \n",
    "    # 3. Executar a consulta para pegar 10 linhas\n",
    "    query = \"SELECT listing_id, calendar_date, listing_price, listing_name FROM silver.one_big_table LIMIT 10;\"\n",
    "    cur.execute(query)\n",
    "    \n",
    "    # 4. Recuperar os resultados\n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    print(f\"--- Exibindo {len(rows)} linhas da tabela silver.one_big_table ---\\n\")\n",
    "    \n",
    "    # 5. Iterar e imprimir de forma organizada\n",
    "    for row in rows:\n",
    "        print(f\"ID: {row['listing_id']} | Data: {row['calendar_date']} | Pre√ßo: ${row['listing_price']} | Nome: {row['listing_name'][:30]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao consultar o banco: {e}\")\n",
    "\n",
    "finally:\n",
    "    # 6. Fechar conex√£o sempre!\n",
    "    if cur: cur.close()\n",
    "    if conn: conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
